{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "Here we will be using keras for digit recognition. We will be using MNIST as our training data for our neural network and then we will test the data and display the results. \n",
    "\n",
    "We will be using numpy to get and store the bytes in an array then we will be using keras to train our neural network.\n",
    "\n",
    "First we take the files taken from:(http://yann.lecun.com/exdb/mnist/) using gzip which is a module that provides open(), compress() and decompress() convenience functions. The GzipFile class reads and writes gzip-format files, automatically compressing or decompressing the data so that it looks like an ordinary file object.\n",
    "\n",
    "Using numpy we convert the files to a 2D array then reshape it to 28X28 every 784 bytes after the first 16 as unsigned intergers using np.uint8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unzipping the file within the script.\n",
    "import gzip\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content_images = f.read()\n",
    "    \n",
    "# For unzipping the file within the script.\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    file_content_labels = f.read()\n",
    "\n",
    "import numpy as np\n",
    "image = ~np.array(list(file_content_images[16:800])).reshape(28,28).astype(np.uint8)\n",
    "\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "    \n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8)/255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://www.inria.fr/var/inria/storage/images/medias/actualites/generales/images-chapo/scikit-learn-chapo/1870065-1-fre-FR/scikit-learn-chapo_vignette.png)\n",
    "Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoding categorical variables and pre processing.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "outputs[0]\n",
    "\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "There are 6 hidden layers made with a dropout layer running sequentially.\n",
    "\n",
    "The model takes in the 28X28 array of 784 where each pixel is a number ranging from 0 to 1 where 0 is black and 1 is white. Each one of these pixels is considered a neuron and passed into the neural network where the greyscale value is the weight.\n",
    "\n",
    "![title](https://achintavarna.files.wordpress.com/2017/11/mnist_2layers.png)\n",
    "\n",
    "\n",
    "![title](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ------- MODEL -------\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout \n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "# Add a hidden layer with 750 neurons.\n",
    "model.add(kr.layers.Dense(units=784, activation='relu', input_dim=784))\n",
    "# Add a hidden layer with 455 neurons.\n",
    "model.add(kr.layers.Dense(units=455, activation='relu'))\n",
    "# Add a hidden layer with 250 neurons.\n",
    "model.add(kr.layers.Dense(units=250, activation='relu'))\n",
    "# Add a hidden layer with 170 neurons.\n",
    "model.add(kr.layers.Dense(units=170, activation='softplus'))\n",
    "# Add a hidden layer with 120 neurons.\n",
    "model.add(kr.layers.Dense(units=120, activation='linear'))\n",
    "# Add a hidden layer with 50 neurons.\n",
    "model.add(kr.layers.Dense(units=50, activation='relu'))\n",
    "# Add a dropout layer every 1 in 5.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 455)               357175    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               114000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 170)               42670     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 120)               20520     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 1,156,365\n",
      "Trainable params: 1,156,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.6597 - acc: 0.7881\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.3070 - acc: 0.9098\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.2297 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.1942 - acc: 0.9432\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 0.1611 - acc: 0.9514\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.1488 - acc: 0.9566\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.1377 - acc: 0.9581\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.1286 - acc: 0.9619\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.1109 - acc: 0.9662\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.1117 - acc: 0.96630s - loss: 0.1119 - acc: 0.966\n"
     ]
    }
   ],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Number of Epoch is the amount of times the training set is put through the model\n",
    "# The batch size is the amount of images the models processes at one time\n",
    "model.fit(inputs, outputs, epochs=10, batch_size=100)\n",
    "\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9571\n"
     ]
    }
   ],
   "source": [
    "# Tests prints the sum of correct predictions out of the 10,000 test images.\n",
    "print((encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "Gzip: https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "Keras: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
