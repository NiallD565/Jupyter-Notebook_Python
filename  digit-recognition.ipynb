{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "Here we will be using keras for digit recognition. We will be using MNIST as our training data for our neural network and then we will test the data and display the results. \n",
    "\n",
    "We will be using numpy to get and store the bytes in an array then we will be using keras to train our neural network.\n",
    "\n",
    "First we take the files taken from:(http://yann.lecun.com/exdb/mnist/) using gzip which is a module that provides open(), compress() and decompress() convenience functions. The GzipFile class reads and writes gzip-format files, automatically compressing or decompressing the data so that it looks like an ordinary file object.\n",
    "\n",
    "Using numpy we convert the files to a 2D array then reshape it to 28X28 every 784 bytes after the first 16 as unsigned intergers using np.uint8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unzipping the file within the script.\n",
    "import gzip\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content_images = f.read()\n",
    "    \n",
    "# For unzipping the file within the script.\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    file_content_labels = f.read()\n",
    "\n",
    "import numpy as np\n",
    "image = ~np.array(list(file_content_images[16:800])).reshape(28,28).astype(np.uint8)\n",
    "\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "    \n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8)/255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoding categorical variables and pre processing.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "outputs[0]\n",
    "\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "There are 6 hidden layers made with a dropout layer running sequentially.\n",
    "\n",
    "The model takes in the 28X28 array of 784 where each pixel is a number ranging from 0 to 1 where 0 is black and 1 is white. Each one of these pixels is considered a neuron and passed into the neural network where the greyscale value is is the weight.\n",
    "\n",
    "![title](https://achintavarna.files.wordpress.com/2017/11/mnist_2layers.png)\n",
    "\n",
    "# Keras\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- MODEL -------\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout \n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "# Add a hidden layer with 750 neurons.\n",
    "model.add(kr.layers.Dense(units=784, activation='relu', input_dim=784))\n",
    "# Add a hidden layer with 455 neurons.\n",
    "model.add(kr.layers.Dense(units=455, activation='relu'))\n",
    "# Add a hidden layer with 250 neurons.\n",
    "model.add(kr.layers.Dense(units=250, activation='relu'))\n",
    "# Add a hidden layer with 170 neurons.\n",
    "model.add(kr.layers.Dense(units=170, activation='softplus'))\n",
    "# Add a hidden layer with 120 neurons.\n",
    "model.add(kr.layers.Dense(units=120, activation='linear'))\n",
    "# Add a hidden layer with 50 neurons.\n",
    "model.add(kr.layers.Dense(units=50, activation='relu'))\n",
    "# Add a dropout layer every 1 in 5.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 455)               357175    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 250)               114000    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 170)               42670     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 120)               20520     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 1,156,365\n",
      "Trainable params: 1,156,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.7181 - acc: 0.7638\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.3017 - acc: 0.9119\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 23s 381us/step - loss: 0.2297 - acc: 0.9315\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.1906 - acc: 0.9443\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 23s 379us/step - loss: 0.1628 - acc: 0.9515\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 23s 388us/step - loss: 0.1498 - acc: 0.9551\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 23s 387us/step - loss: 0.1345 - acc: 0.9601\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.1210 - acc: 0.9630\n"
     ]
    }
   ],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Number of Epoch is the amount of times the training set is put through the model\n",
    "# The batch size is the amount of images the models processes at one time\n",
    "model.fit(inputs, outputs, epochs=8, batch_size=100)\n",
    "\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9654\n"
     ]
    }
   ],
   "source": [
    "print((encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "Gzip: https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "Keras: https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
